{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import sin, cos\n",
    "import numba as nb\n",
    "from scipy.optimize import fsolve\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# power flow function (equality constraints)\n",
    "def gfun(x, u, p):\n",
    "  \n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "    VA2 = x[2]\n",
    "    P1  = x[3]\n",
    "    \n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "    VM2 = u[2]\n",
    "    \n",
    "    VA1 = p[0]\n",
    "    P3 = p[1]\n",
    "    Q3 = p[2]\n",
    "\n",
    "    # intermediate quantities\n",
    "    VA23 = VA2 - VA3\n",
    "    VA31 = VA3 - VA1\n",
    "    VA32 = VA3 - VA2\n",
    "    VA13 = VA1 - VA3\n",
    "    \n",
    "    F1 = 4.0*VM2*VM2 + VM2*VM3*(-4*cos(VA23) + 10*sin(VA23)) - P2\n",
    "    F2 = (8.0*VM3*VM3 + VM3*VM1*(-4*cos(VA31) + 5*sin(VA31))\n",
    "          + VM3*VM2*(-4*cos(VA32) + 10*sin(VA32)) + P3)\n",
    "    F3 = (15.0*VM3*VM3 + VM3*VM1*(-4*sin(VA31) - 5*cos(VA31))\n",
    "          + VM3*VM2*(-4*sin(VA32) - 10*cos(VA32)) + Q3)\n",
    "    F4 = 4.0*VM1*VM1 + VM1*VM3*(-4*cos(VA13) + 5*sin(VA13)) - P1\n",
    "    \n",
    "    \n",
    "    return np.array([F1, F2, F3, F4])\n",
    "\n",
    "# cost function\n",
    "def cfun(x, u, p):\n",
    "\n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "    P1 = x[3]\n",
    "\n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "\n",
    "    VA1 = p[0]\n",
    "\n",
    "    VA13 = VA1 - VA3\n",
    "    \n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    \n",
    "    cost = P1 + P2\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jacobians and gradients\n",
    "\n",
    "def gfun_x(x, u, p):\n",
    "\n",
    "    \n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "    VA2 = x[2]\n",
    "    \n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "    VM2 = u[2]\n",
    "    \n",
    "    VA1 = p[0]\n",
    "    P3 = p[1]\n",
    "    Q3 = p[2]\n",
    "\n",
    "    # intermediate quantities\n",
    "    VA23 = VA2 - VA3\n",
    "    VA31 = VA3 - VA1\n",
    "    VA32 = VA3 - VA2\n",
    "    \n",
    "    J = np.zeros((4, 4))\n",
    "    \n",
    "    #F1\n",
    "    J[0, 0] =  VM2*(10*sin(VA2 - VA3) - 4*cos(VA2 - VA3))\n",
    "    J[0, 1] =  VM2*VM3*(-4*sin(VA2 - VA3) - 10*cos(VA2 - VA3))\n",
    "    J[0, 2] =  VM2*VM3*(4*sin(VA2 - VA3) + 10*cos(VA2 - VA3))\n",
    "    J[0, 3] =  0\n",
    "    #F2\n",
    "    J[1, 0] =  VM1*(-5*sin(VA1 - VA3) - 4*cos(VA1 - VA3)) + VM2*(-10*sin(VA2 - VA3) - 4*cos(VA2 - VA3)) + 16.0*VM3\n",
    "    J[1, 1] =  VM1*VM3*(-4*sin(VA1 - VA3) + 5*cos(VA1 - VA3)) + VM2*VM3*(-4*sin(VA2 - VA3) + 10*cos(VA2 - VA3))\n",
    "    J[1, 2] =  VM2*VM3*(4*sin(VA2 - VA3) - 10*cos(VA2 - VA3))\n",
    "    J[1, 3] =  0\n",
    "    #F3\n",
    "    J[2, 0] =  VM1*(4*sin(VA1 - VA3) - 5*cos(VA1 - VA3)) + VM2*(4*sin(VA2 - VA3) - 10*cos(VA2 - VA3)) + 30.0*VM3\n",
    "    J[2, 1] =  VM1*VM3*(-5*sin(VA1 - VA3) - 4*cos(VA1 - VA3)) + VM2*VM3*(-10*sin(VA2 - VA3) - 4*cos(VA2 - VA3))\n",
    "    J[2, 2] =  VM2*VM3*(10*sin(VA2 - VA3) + 4*cos(VA2 - VA3))\n",
    "    J[2, 3] =  0\n",
    "    #F4\n",
    "    J[3, 0] =  VM1*(5*sin(VA1 - VA3) - 4*cos(VA1 - VA3))\n",
    "    J[3, 1] =  VM1*VM3*(-4*sin(VA1 - VA3) - 5*cos(VA1 - VA3))\n",
    "    J[3, 2] =  0\n",
    "    J[3, 3] =  -1\n",
    "\n",
    "\n",
    "    return J\n",
    "\n",
    "def gfun_u(x, u, p):\n",
    "    \n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "    VA2 = x[2]\n",
    "    \n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "    VM2 = u[2]\n",
    "    \n",
    "    VA1 = p[0]\n",
    "    P3 = p[1]\n",
    "    Q3 = p[2]\n",
    "\n",
    "    # intermediate quantities\n",
    "    VA23 = VA2 - VA3\n",
    "    VA31 = VA3 - VA1\n",
    "    VA32 = VA3 - VA2\n",
    "    \n",
    "    J = np.zeros((4, 3))\n",
    "    \n",
    "    #F1\n",
    "    J[0, 0] =  0\n",
    "    J[0, 1] =  -1\n",
    "    J[0, 2] =  8.0*VM2 + VM3*(10*sin(VA2 - VA3) - 4*cos(VA2 - VA3))\n",
    "    #F2\n",
    "    J[1, 0] =  VM3*(-5*sin(VA1 - VA3) - 4*cos(VA1 - VA3))\n",
    "    J[1, 1] =  0\n",
    "    J[1, 2] =  VM3*(-10*sin(VA2 - VA3) - 4*cos(VA2 - VA3))\n",
    "    #F3\n",
    "    J[2, 0] =  VM3*(4*sin(VA1 - VA3) - 5*cos(VA1 - VA3))\n",
    "    J[2, 1] =  0\n",
    "    J[2, 2] =  VM3*(4*sin(VA2 - VA3) - 10*cos(VA2 - VA3))\n",
    "    #F4\n",
    "    J[3, 0] =  8.0*VM1 + VM3*(5*sin(VA1 - VA3) - 4*cos(VA1 - VA3))\n",
    "    J[3, 1] =  0\n",
    "    J[3, 2] =  0\n",
    "\n",
    "    return J\n",
    "\n",
    "\n",
    "def cfun_x(x, u, p):\n",
    "    \n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "\n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "\n",
    "    VA1 = p[0]\n",
    "\n",
    "    VA13 = VA1 - VA3\n",
    "    \n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    \n",
    "    grad = np.zeros(4)\n",
    "    grad[0] =  0\n",
    "    grad[1] =  0\n",
    "    grad[2] =  0\n",
    "    grad[3] =  w1\n",
    "\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def cfun_u(x, u, p):\n",
    "    \n",
    "    VM3 = x[0]\n",
    "    VA3 = x[1]\n",
    "\n",
    "    VM1 = u[0]\n",
    "    P2 = u[1]\n",
    "\n",
    "    VA1 = p[0]\n",
    "\n",
    "    VA13 = VA1 - VA3\n",
    "    \n",
    "    w1 = 1.0\n",
    "    w2 = 1.0\n",
    "    \n",
    "    grad = np.zeros(3)\n",
    "    grad[0] =  0\n",
    "    grad[1] =  w2\n",
    "    grad[2] =  0\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize script with same initial conditions as in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.  0.  0.5]\n",
      "[1.  1.7 1. ]\n"
     ]
    }
   ],
   "source": [
    "# initial parameters\n",
    "x = np.zeros(4)\n",
    "u = np.zeros(3)\n",
    "p = np.zeros(3)\n",
    "\n",
    "# this is given by the problem data, but might be \"controlled\" via OPF\n",
    "u[0] = 1.0 #VM1\n",
    "u[1] = 1.7 #P2\n",
    "u[2] = 1.0 #VM2\n",
    "\n",
    "# these parameters are fixed through the computation\n",
    "p[0] = 0.0 #VA1, slack angle\n",
    "p[1] = 2.0 #P3\n",
    "p[2] = 1.0 #Q3\n",
    "\n",
    "\n",
    "# initial guess\n",
    "x[0] = 1.0 #VM3\n",
    "x[1] = 0.0 #VA3\n",
    "x[2] = 0.0 #VA2\n",
    "x[3] = 0.5\n",
    "\n",
    "\n",
    "# print initial guesses\n",
    "print(x)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88186783 -0.00094814  0.1349708   0.47671095]\n",
      "44.553094929145\n"
     ]
    }
   ],
   "source": [
    "# POWER FLOW ALGO\n",
    "\n",
    "def powerflow(x, u, p):\n",
    "    \n",
    "    sol = fsolve(gfun, x, args=(u,p,))\n",
    "    return sol\n",
    "\n",
    "print(powerflow(x, u, p))\n",
    "\n",
    "print(np.linalg.cond(gfun_x(x, u, p)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "condition jacobian: 39.59958561633352\n",
      "Norm of gradient:  0.7038831242740287\n",
      "Cost function:  2.1767109512499543\n",
      "condition jacobian: 46.68308341866992\n",
      "Norm of gradient:  0.5531510420686726\n",
      "Cost function:  2.1598296133612314\n",
      "condition jacobian: 44.71393962254119\n",
      "Norm of gradient:  0.4450119712664789\n",
      "Cost function:  2.149087109860759\n",
      "condition jacobian: 49.48699914092949\n",
      "Norm of gradient:  0.3506100402295171\n",
      "Cost function:  2.1398376900170497\n",
      "condition jacobian: 48.99354430244175\n",
      "Norm of gradient:  0.2865642394328765\n",
      "Cost function:  2.1329741612923963\n",
      "condition jacobian: 52.204220536784455\n",
      "Norm of gradient:  0.23911203526530678\n",
      "Cost function:  2.127220777411127\n",
      "condition jacobian: 52.614602175128354\n",
      "Norm of gradient:  0.2081087508231566\n",
      "Cost function:  2.122449802647705\n",
      "condition jacobian: 54.89049527130433\n",
      "Norm of gradient:  0.186821075858742\n",
      "Cost function:  2.1183014665515123\n",
      "condition jacobian: 55.76733748285113\n",
      "Norm of gradient:  0.17233726046432105\n",
      "Cost function:  2.1146440807183913\n",
      "condition jacobian: 57.517761961644126\n",
      "Norm of gradient:  0.16176739144917257\n",
      "Cost function:  2.111356650500203\n",
      "condition jacobian: 58.597077008707025\n",
      "Norm of gradient:  0.15359992547782833\n",
      "Cost function:  2.108370948566132\n",
      "condition jacobian: 60.05672776046317\n",
      "Norm of gradient:  0.14688195885937058\n",
      "Cost function:  2.1056346163804003\n",
      "condition jacobian: 61.19998947768866\n",
      "Norm of gradient:  0.14110267936296644\n",
      "Cost function:  2.1031110645244735\n",
      "condition jacobian: 62.49361986430626\n",
      "Norm of gradient:  0.13597886656650462\n",
      "Cost function:  2.100771448392927\n",
      "condition jacobian: 63.6358841796201\n",
      "Norm of gradient:  0.13134634254972355\n",
      "Cost function:  2.0985931776220133\n",
      "condition jacobian: 64.82721988375019\n",
      "Norm of gradient:  0.12710903336177481\n",
      "Cost function:  2.096557590000047\n",
      "condition jacobian: 65.94164124254631\n",
      "Norm of gradient:  0.12320176952401694\n",
      "Cost function:  2.094649213083336\n",
      "condition jacobian: 67.06306429716629\n",
      "Norm of gradient:  0.11957982356035071\n",
      "Cost function:  2.0928548900025827\n",
      "condition jacobian: 68.14075328764243\n",
      "Norm of gradient:  0.11620798518460776\n",
      "Cost function:  2.0911633901349673\n",
      "condition jacobian: 69.20929226404606\n",
      "Norm of gradient:  0.11305862361446806\n",
      "Cost function:  2.0895649975887016\n",
      "condition jacobian: 70.24909837997838\n",
      "Norm of gradient:  0.11010832690314051\n",
      "Cost function:  2.0880512745057307\n",
      "condition jacobian: 71.27441517553825\n",
      "Norm of gradient:  0.10733745042657401\n",
      "Cost function:  2.0866148308197374\n",
      "condition jacobian: 72.27815785848381\n",
      "Norm of gradient:  0.10472889956465022\n",
      "Cost function:  2.0852491687459787\n",
      "condition jacobian: 73.26634612471608\n",
      "Norm of gradient:  0.10226789191888956\n",
      "Cost function:  2.083948541521328\n",
      "condition jacobian: 74.23674748042754\n",
      "Norm of gradient:  0.09994141456120262\n",
      "Cost function:  2.0827078465661693\n",
      "condition jacobian: 75.19209071063335\n",
      "Norm of gradient:  0.09773803318556058\n",
      "Cost function:  2.0815225327208537\n",
      "condition jacobian: 76.13195102613078\n",
      "Norm of gradient:  0.09564760237412037\n",
      "Cost function:  2.080388525905644\n",
      "condition jacobian: 77.05773348390454\n",
      "Norm of gradient:  0.09366111243783634\n",
      "Cost function:  2.0793021654170034\n",
      "condition jacobian: 77.96964260456915\n",
      "Norm of gradient:  0.09177051370178724\n",
      "Cost function:  2.078260151208318\n",
      "condition jacobian: 78.86853337400298\n",
      "Norm of gradient:  0.08996859911833531\n",
      "Cost function:  2.0772594987850588\n",
      "condition jacobian: 79.75479800130043\n",
      "Norm of gradient:  0.08824888844427461\n",
      "Cost function:  2.076297501123212\n",
      "condition jacobian: 80.62904459667439\n",
      "Norm of gradient:  0.0866055403965747\n",
      "Cost function:  2.075371695960047\n",
      "condition jacobian: 81.49169489414548\n",
      "Norm of gradient:  0.0850332720803518\n",
      "Cost function:  2.074479837798036\n",
      "condition jacobian: 82.34323069405875\n",
      "Norm of gradient:  0.0835272936062179\n",
      "Cost function:  2.0736198737109612\n",
      "condition jacobian: 83.1840511772132\n",
      "Norm of gradient:  0.08208324999183435\n",
      "Cost function:  2.0727899224226003\n",
      "condition jacobian: 84.01456203954248\n",
      "Norm of gradient:  0.08069717226480981\n",
      "Cost function:  2.071988256104929\n",
      "condition jacobian: 84.83512616001266\n",
      "Norm of gradient:  0.07936543449686252\n",
      "Cost function:  2.071213284507332\n",
      "condition jacobian: 85.64609608194202\n",
      "Norm of gradient:  0.07808471688758647\n",
      "Cost function:  2.0704635410573493\n",
      "condition jacobian: 86.44779771332928\n",
      "Norm of gradient:  0.07685197337762385\n",
      "Cost function:  2.069737670655341\n",
      "condition jacobian: 87.24054253650857\n",
      "Norm of gradient:  0.07566440346388836\n",
      "Cost function:  2.0690344189187813\n",
      "condition jacobian: 88.02462276360689\n",
      "Norm of gradient:  0.07451942740836691\n",
      "Cost function:  2.0683526226782005\n",
      "condition jacobian: 88.80031628427878\n",
      "Norm of gradient:  0.07341466447194495\n",
      "Cost function:  2.0676912015539965\n",
      "condition jacobian: 89.56788567088942\n",
      "Norm of gradient:  0.07234791368773312\n",
      "Cost function:  2.067049150471505\n",
      "condition jacobian: 90.32758048102441\n",
      "Norm of gradient:  0.07131713686523354\n",
      "Cost function:  2.0664255329922763\n",
      "condition jacobian: 91.07963747739987\n",
      "Norm of gradient:  0.07032044350673848\n",
      "Cost function:  2.065819475358139\n",
      "condition jacobian: 91.82428192000147\n",
      "Norm of gradient:  0.06935607739809045\n",
      "Cost function:  2.0652301611588646\n",
      "condition jacobian: 92.56172810979038\n",
      "Norm of gradient:  0.06842240465243367\n",
      "Cost function:  2.0646568265476417\n",
      "condition jacobian: 93.29218025460041\n",
      "Norm of gradient:  0.06751790302820763\n",
      "Cost function:  2.0640987559385215\n",
      "condition jacobian: 94.01583304835579\n",
      "Norm of gradient:  0.06664115236218988\n",
      "Cost function:  2.0635552781292477\n",
      "condition jacobian: 94.73287232604724\n",
      "Norm of gradient:  0.06579082598379983\n",
      "Cost function:  2.063025762800346\n",
      "condition jacobian: 95.44347559420805\n",
      "Norm of gradient:  0.06496568299342499\n",
      "Cost function:  2.0625096173479123\n",
      "condition jacobian: 96.1478125602563\n",
      "Norm of gradient:  0.06416456130436077\n",
      "Cost function:  2.0620062840129574\n",
      "condition jacobian: 96.84604559676049\n",
      "Norm of gradient:  0.06338637136058649\n",
      "Cost function:  2.0615152372748167\n",
      "condition jacobian: 97.53833018359235\n",
      "Norm of gradient:  0.06263009045432247\n",
      "Cost function:  2.0610359814802464\n",
      "condition jacobian: 98.2248153088795\n",
      "Norm of gradient:  0.06189475757695367\n",
      "Cost function:  2.060568048683507\n",
      "condition jacobian: 98.90564384461926\n",
      "Norm of gradient:  0.06117946874515524\n",
      "Cost function:  2.060110996675125\n",
      "condition jacobian: 99.58095289230118\n",
      "Norm of gradient:  0.06048337275143542\n",
      "Cost function:  2.0596644071804695\n",
      "condition jacobian: 100.25087410513177\n",
      "Norm of gradient:  0.05980566729418851\n",
      "Cost function:  2.0592278842107525\n",
      "condition jacobian: 100.91553398664031\n",
      "Norm of gradient:  0.05914559544808389\n",
      "Cost function:  2.0588010525514906\n",
      "condition jacobian: 101.57505416896299\n",
      "Norm of gradient:  0.05850244243986449\n",
      "Cost function:  2.058383556375042\n",
      "condition jacobian: 102.22955167178307\n",
      "Norm of gradient:  0.057875532698962166\n",
      "Cost function:  2.0579750579652494\n",
      "condition jacobian: 102.87913914393975\n",
      "Norm of gradient:  0.05726422715568419\n",
      "Cost function:  2.0575752365436575\n",
      "condition jacobian: 103.52392508889105\n",
      "Norm of gradient:  0.05666792076277529\n",
      "Cost function:  2.0571837871877476\n",
      "condition jacobian: 104.16401407544895\n",
      "Norm of gradient:  0.05608604021895701\n",
      "Cost function:  2.056800419832891\n",
      "condition jacobian: 104.79950693488531\n",
      "Norm of gradient:  0.05551804187526648\n",
      "Cost function:  2.0564248583502907\n",
      "condition jacobian: 105.43050094551025\n",
      "Norm of gradient:  0.05496340980712143\n",
      "Cost function:  2.0560568396942185\n",
      "condition jacobian: 106.05709000566179\n",
      "Norm of gradient:  0.054421654036911155\n",
      "Cost function:  2.0556961131124587\n",
      "condition jacobian: 106.6793647960009\n",
      "Norm of gradient:  0.05389230889332929\n",
      "Cost function:  2.05534243941444\n",
      "condition jacobian: 107.2974129318981\n",
      "Norm of gradient:  0.053374931495360066\n",
      "Cost function:  2.0549955902921337\n",
      "condition jacobian: 107.91131910665553\n",
      "Norm of gradient:  0.052869100349759474\n",
      "Cost function:  2.054655347689286\n",
      "condition jacobian: 108.52116522621934\n",
      "Norm of gradient:  0.052374414052233816\n",
      "Cost function:  2.0543215032148865\n",
      "condition jacobian: 109.12703053600187\n",
      "Norm of gradient:  0.05189049008335873\n",
      "Cost function:  2.0539938575973475\n",
      "condition jacobian: 109.72899174036381\n",
      "Norm of gradient:  0.05141696369119191\n",
      "Cost function:  2.053672220175985\n",
      "condition jacobian: 110.32712311528263\n",
      "Norm of gradient:  0.0509534868533069\n",
      "Cost function:  2.0533564084268647\n",
      "condition jacobian: 110.92149661466131\n",
      "Norm of gradient:  0.050499727311726916\n",
      "Cost function:  2.0530462475202973\n",
      "condition jacobian: 111.5121819707246\n",
      "Norm of gradient:  0.05005536767471475\n",
      "Cost function:  2.052741569907472\n",
      "condition jacobian: 112.09924678889266\n",
      "Norm of gradient:  0.049620104580068165\n",
      "Cost function:  2.052442214934024\n",
      "condition jacobian: 112.68275663750681\n",
      "Norm of gradient:  0.049193647915060895\n",
      "Cost function:  2.0521480284784124\n",
      "condition jacobian: 113.2627751327343\n",
      "Norm of gradient:  0.04877572008844989\n",
      "Cost function:  2.051858862613359\n",
      "condition jacobian: 113.83936401897739\n",
      "Norm of gradient:  0.04836605535062367\n",
      "Cost function:  2.051574575288501\n",
      "condition jacobian: 114.41258324506592\n",
      "Norm of gradient:  0.04796439915807947\n",
      "Cost function:  2.0512950300327444\n",
      "condition jacobian: 114.98249103650815\n",
      "Norm of gradient:  0.04757050757893148\n",
      "Cost function:  2.0510200956749207\n",
      "condition jacobian: 115.5491439640374\n",
      "Norm of gradient:  0.04718414673634168\n",
      "Cost function:  2.050749646081412\n",
      "condition jacobian: 116.11259700869448\n",
      "Norm of gradient:  0.04680509228701305\n",
      "Cost function:  2.0504835599094253\n",
      "condition jacobian: 116.67290362365212\n",
      "Norm of gradient:  0.046433128932262716\n",
      "Cost function:  2.0502217203750908\n",
      "condition jacobian: 117.23011579297565\n",
      "Norm of gradient:  0.0460680499592024\n",
      "Cost function:  2.04996401503497\n",
      "condition jacobian: 117.78428408751607\n",
      "Norm of gradient:  0.0457096568099303\n",
      "Cost function:  2.0497103355804254\n",
      "condition jacobian: 118.33545771808662\n",
      "Norm of gradient:  0.04535775867671949\n",
      "Cost function:  2.0494605776436896\n",
      "condition jacobian: 118.88368458610115\n",
      "Norm of gradient:  0.04501217212136603\n",
      "Cost function:  2.0492146406150438\n",
      "condition jacobian: 119.42901133180803\n",
      "Norm of gradient:  0.04467272071703534\n",
      "Cost function:  2.048972427470229\n",
      "condition jacobian: 119.97148338026396\n",
      "Norm of gradient:  0.04433923471104062\n",
      "Cost function:  2.0487338446074905\n",
      "condition jacobian: 120.51114498517302\n",
      "Norm of gradient:  0.04401155070712215\n",
      "Cost function:  2.048498801693592\n",
      "condition jacobian: 121.04803927071465\n",
      "Norm of gradient:  0.043689511365930744\n",
      "Cost function:  2.0482672115182634\n",
      "condition jacobian: 121.58220827146721\n",
      "Norm of gradient:  0.043372965122509544\n",
      "Cost function:  2.048038989856467\n",
      "condition jacobian: 122.11369297053665\n",
      "Norm of gradient:  0.043061765919578145\n",
      "Cost function:  2.0478140553380566\n",
      "condition jacobian: 122.64253333598617\n",
      "Norm of gradient:  0.04275577295567556\n",
      "Cost function:  2.0475923293243463\n",
      "condition jacobian: 123.16876835565805\n",
      "Norm of gradient:  0.04245485044717002\n",
      "Cost function:  2.0473737357911275\n",
      "condition jacobian: 123.69243607047382\n",
      "Norm of gradient:  0.042158867403189075\n",
      "Cost function:  2.047158201217772\n",
      "condition jacobian: 124.21357360629553\n",
      "Norm of gradient:  0.0418676974127559\n",
      "Cost function:  2.0469456544820805\n",
      "condition jacobian: 124.73221720441977\n",
      "Norm of gradient:  0.041581218443233245\n",
      "Cost function:  2.0467360267604255\n"
     ]
    }
   ],
   "source": [
    "# Reduced gradient iteration\n",
    "\n",
    "max_iter = 100\n",
    "xk = np.copy(x)\n",
    "uk = np.copy(u)\n",
    "\n",
    "for i in range(max_iter):\n",
    "    \n",
    "    # power flow\n",
    "    xk = powerflow(xk, uk, p)\n",
    "\n",
    "    # lambda calculation\n",
    "    J_x = gfun_x(xk, uk, p)\n",
    "    G_x = cfun_x(xk, uk, p)\n",
    "    print(\"condition jacobian:\", np.linalg.cond(J_x))\n",
    "    lam = -np.dot(inv(np.transpose(J_x)), G_x)\n",
    "    \n",
    "    # gradient cost function\n",
    "    J_u = gfun_u(xk, uk, p)\n",
    "    G_u = cfun_u(xk, uk, p)\n",
    "    \n",
    "    grad_c = G_u + np.dot(np.transpose(J_u), lam)\n",
    "    print(\"Norm of gradient: \", np.linalg.norm(grad_c))\n",
    "    \n",
    "    # evaluate cost function\n",
    "    print(\"Cost function: \", cfun(xk, uk, p))    \n",
    "    \n",
    "    # compute step\n",
    "    alpha = 0.12\n",
    "    uk = uk - alpha*grad_c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
